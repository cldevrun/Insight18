# This is the K8s yaml config file that can 
# create a namenode for the Hadoop File System
# The namenode is what the client will interact with to 
# store data within HDFS, and commands the datanodes to do
# the actual compressed file store.
apiVersion: v1
# The services to expose the namenode pod through port 50070 and 8020
# By default, pods are closed externally unless you create a service
# to expose those pod ports. 
kind: Service
metadata:
  name: hdfs-namenode
  labels:
    app: hdfs-namenode
spec:
  ports:
  # Port 50070 is used for the HDFS web ui
  - protocol: TCP
    port: 50070
    targetPort: 50070
    name: ui
  # Port 8020 is used by namenode to communicate with its datanodes
  # Under all circumstances, DON'T TOUCH unless you know what
  # you're doing, otherwise HDFS will fail
  - protocol: TCP
    port: 8020
    targetPort: 8020
    name: metadata
  selector:
    app: hdfs-namenode
---
# Namenode pod creation, where the image will be pulled
# from uhopper, be configured with the following environment
# variables, and have port 8020 open so that the namenode
# can communicate with its datanodes.
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: hdfs-namenode
spec:
  serviceName: "hdfs-namenode"
  replicas: 1
  template:
    metadata:
      labels:
        app: hdfs-namenode
    spec:
      terminationGracePeriodSeconds: 0
      containers:
        - name: hdfs-namenode
          image: uhopper/hadoop-namenode:2.7.2
          env:
            - name: CLUSTER_NAME
              value: hdfs-k8s
            - name: HDFS_CONF_dfs_permissions
              value: 'false'
            - name: HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check
              value: 'false'
            
          ports:
          # 8020 should never change. If you use any other port
          # HDFS firewall port rules will prevent any communication
          # from coming through
          - containerPort: 8020
            name: fs
      restartPolicy: Always
